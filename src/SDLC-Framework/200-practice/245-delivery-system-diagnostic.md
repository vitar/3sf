# Delivery System Diagnostic

> *“A healthy system adapts before it breaks.”*

### Purpose

The **Delivery System Diagnostic** is applied early in the project (typically after 4–6 weeks of active work) to verify whether the **designed delivery system** performs as expected.

Its goal is to:

- Detect **systemic friction** or **relationship gaps** between Client and Vendor,
- Evaluate alignment between **intent, flow, and value**,
- Identify which **3SF layers** need adjustment before scaling or acceleration.

This tool bridges the transition from *planned system* (design intent) to *observed system* (actual operation).

### Applies To

| Dimension | Scope |
|------------|-------|
| **SDLC Stages** | Discovery → Early Delivery |
| **3SF Relationship Lines** | Engagement ↔ Delivery ↔ Value |
| **3SF Layers** | Contextual Drivers Layer (CDL) + Stable Rules Layer (SRL) |
| **Maturity Target** | From *Collaborative Confidence* → toward *Co-Creative Trust* |

### Actors / Roles

| Client Side | Vendor Side | Shared Purpose |
|--------------|--------------|----------------|
| **Product Leader** | **Delivery Facilitator** | Ensure delivery aligns with business value and maintains flow. |
| **Solution Architect** | **Solution Architect** | Validate architectural and technical integrity. |
| **Requirements Analyst** | **Requirements Analyst** | Verify clarity, scope flow, and requirement traceability. |
| **Governance Officer** | **Engineering Director** | Check compliance, access, and operational readiness. |
| **Executive Sponsor** | **Account Lead** | Evaluate relationship maturity and system health. |

### Steps / Routines

#### 1. **Collect Observations**

- Review how work actually flows through the system.
- Compare to the designed model from the **Initial Delivery System Design**.
- Capture evidence: velocity trends, dependency logs, unresolved impediments.

#### 2. **Assess Relationship Lines**

- **Engagement Line:** Are expectations and communication loops effective?
- **Delivery Line:** Are teams collaborating fluidly, or bottlenecks emerging?
- **Value Line:** Is delivered output translating into business outcomes?

#### 3. **Identify Maturity Gaps**

- Apply the **3SF Maturity Diagnostic Grid** (simplified per relationship line).
- Rate each on a 1–5 maturity scale (Reactive → Strategic).
- Record differences between *planned* and *actual* maturity.

#### 4. **Map Systemic Constraints**

- Analyze internal dependencies (e.g., security approvals, environment setup).
- Document external ones (e.g., vendor staffing, client change management).
- Tag each as *short-term fix* or *systemic risk*.

#### 5. **Facilitate Review Session**

- Conduct a 90-minute joint workshop led by the Delivery Facilitator and Product Leader.
- Discuss each constraint and decide what should be improved, delegated, or postponed.
- Prioritize no more than three systemic improvement actions.

#### 6. **Publish Diagnostic Report**

- Summarize observations, ratings, and actions in a **Delivery Diagnostic Sheet**.
- Share with both organizations’ leadership (Account Lead + Executive Sponsor).

### Inputs / Outputs

| Inputs | Outputs |
|---------|----------|
| Delivery Charter, Engagement Canvas, Maturity Baseline | **Delivery Diagnostic Sheet**, **Maturity Delta Report**, updated **Improvement Backlog** |

### Metrics / Signals

| Category | Example Indicators |
|-----------|--------------------|
| **Flow Efficiency** | <10% work blocked or delayed >3 days. |
| **Dependency Visibility** | All cross-org dependencies tracked and owned. |
| **Decision Latency** | Average turnaround time < 48 hours for delivery-critical decisions. |
| **Maturity Delta** | Gap between designed and actual maturity ≤ 1 level per relationship line. |
| **Engagement Pulse** | Positive sentiment trend in post-review survey (≥ 4/5). |

### Common Pitfalls

- Treating observed delivery issues as *team performance* instead of *systemic friction*.
- Focusing only on process metrics (velocity, defects) instead of relationship quality.
- Overloading the session with too many improvement goals.
- Conducting the review without both client and vendor decision-makers present.
- Ignoring early warning signs in engagement tone or feedback cadence.

### Scaling Notes

| Maturity Stage | Evolution Focus |
|----------------|-----------------|
| **Collaborative → Co-Creative** | Joint backlog ownership, transparent metrics dashboards. |
| **Co-Creative → Strategic Partner** | Shared outcome KPIs replacing output metrics. |

As maturity increases, the diagnostic evolves from *problem detection* to *continuous improvement ritual*.

### Client-Side Application

**Objective:** Confirm that the vendor delivery system effectively contributes to intended business outcomes.

**Client actions**

1. Review progress against expectations defined in the Delivery Charter.
2. Provide transparent feedback on value realization, not just output volume.
3. Identify internal blockers that affect vendor performance (e.g., approvals, access).
4. Participate in the joint diagnostic workshop; focus on shared system ownership.
5. Approve improvement actions that require internal resource or policy change.

### Vendor-Side Application

**Objective:** Detect early misalignments and demonstrate delivery accountability through data and transparency.

**Vendor actions**

1. Collect delivery flow metrics and prepare the Maturity Delta Report.
2. Facilitate the diagnostic workshop using 3SF templates.
3. Document agreed actions with clear ownership (Client or Vendor).
4. Present findings constructively — emphasizing collaboration, not blame.
5. Integrate improvement items into the next quarterly plan or sprint retrospectives.

### Summary

The **Delivery System Diagnostic** ensures that the joint delivery system is *functional, adaptive, and value-aligned*.<br/>
It transforms early-stage ambiguity into structured learning and continuous improvement.

Used effectively, it becomes a **trust accelerator** — validating that both Client and Vendor are learning *with each other*, not *about each other*.
